{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fasttextipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPiZx6H1dQdT",
        "outputId": "d55b4d38-68e8-4721-d177-c57ab3fb1b27"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fasttext in /usr/local/lib/python3.7/dist-packages (0.9.2)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext) (2.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mUUpIerhcNc9",
        "outputId": "4298f7d6-c20c-4927-ef47-b2c06bd7ebd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from collections import defaultdict\n",
        "import os, re, csv, math, codecs\n",
        "from tqdm import tqdm\n",
        "\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.layers import Dense, GlobalAveragePooling1D, Embedding\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn import model_selection\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import io\n",
        "from tqdm import tqdm\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer \n",
        "import os, re, csv, math, codecs\n",
        "from sklearn import model_selection\n",
        "from sklearn import metrics\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import tensorflow as tf  # we use both tensorflow and pytorch (pytorch for main part) , tensorflow for tokenizer\n",
        "\n",
        "torch.manual_seed(42);\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from gensim.models.fasttext import FastText\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nltk\n",
        "from string import punctuation\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk import WordPunctTokenizer\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "en_stop = set(nltk.corpus.stopwords.words('turkish'))\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.read_csv(\"sample.csv\")"
      ],
      "metadata": {
        "id": "NmiQe_1JcYiS"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.sample(frac=1).reset_index(drop=True)\n"
      ],
      "metadata": {
        "id": "cY9DZV__coGr"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentiments(df):\n",
        "  if df['yildizSayisi'] > 3.9:\n",
        "    return 'positive'\n",
        "  elif df['yildizSayisi'] <= 3.0:\n",
        "    return 'negative'\n",
        "data['sentiment'] = data.apply(sentiments, axis=1)"
      ],
      "metadata": {
        "id": "KlVQ_teHcpRJ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert sentiment columns to numerical values\n",
        "data.sentiment = data.sentiment.apply(lambda x: 1 if x=='positive' else 0)\n",
        "## Cross validation \n",
        "# create new column \"kfold\" and assign a random value\n",
        "data['kfold'] = -1\n",
        "# Random the rows of data\n",
        "data = data.sample(frac=1).reset_index(drop=True)\n",
        "# get label\n",
        "y = data.sentiment.values\n",
        "# initialize kfold\n",
        "kf = model_selection.StratifiedKFold(n_splits=5)\n",
        "# fill the new values to kfold column\n",
        "for fold, (train_, valid_) in enumerate(kf.split(X=data, y=y)):\n",
        "    data.loc[valid_, 'kfold'] = fold"
      ],
      "metadata": {
        "id": "1pBZebVFcrDZ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "1A5sAC0gcssx",
        "outputId": "2d49c225-62df-4c53-8884-e07f8df0d3a4"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>yildizSayisi</th>\n",
              "      <th>yorum</th>\n",
              "      <th>yorumLike</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>kfold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>makinaya havlu veya fazla çamaşır attığımda ti...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>Ürün güzel yanlız tek kötü yanı saçı çekiştirm...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>sorunsuz çalişıyor</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>Sorunsuz hizli sekilde teslim aldim. Tasarim o...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>Teknoloji işi şans biraz  çok memnun olan arka...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>3</td>\n",
              "      <td>henüz denemedim kargo başarılıydı fakat keşke ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>5</td>\n",
              "      <td>ürünün kendisini.ısmarladım .ama beyazı ğeldi....</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>2</td>\n",
              "      <td>Fiyat gümüş bi kipe için gayet iyi ama küpe ya...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>2</td>\n",
              "      <td>Birkaç kez kullanılabiliyor hemen karardı</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>2</td>\n",
              "      <td>gzeldi  ama saclarm ince die değiştmm düzlesmedi</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       yildizSayisi  ... kfold\n",
              "0                 4  ...     0\n",
              "1                 3  ...     0\n",
              "2                 5  ...     0\n",
              "3                 5  ...     0\n",
              "4                 2  ...     0\n",
              "...             ...  ...   ...\n",
              "49995             3  ...     4\n",
              "49996             5  ...     4\n",
              "49997             2  ...     4\n",
              "49998             2  ...     4\n",
              "49999             2  ...     4\n",
              "\n",
              "[50000 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.tr.300.vec.gz\n",
        "!gunzip -k cc.tr.300.vec.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QMAR5Wgu9d0",
        "outputId": "d7e2722b-fcaa-4557-bd9b-d3140ef7fc61"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-10 20:07:35--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.tr.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.75.142, 172.67.9.4, 104.22.74.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.75.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1261500728 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.tr.300.vec.gz.1’\n",
            "\n",
            "cc.tr.300.vec.gz.1  100%[===================>]   1.17G  19.8MB/s    in 65s     \n",
            "\n",
            "2021-12-10 20:08:40 (18.5 MB/s) - ‘cc.tr.300.vec.gz.1’ saved [1261500728/1261500728]\n",
            "\n",
            "gzip: cc.tr.300.vec already exists; do you wish to overwrite (y or n)? y\n",
            "y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove*.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEVvWjkRwt4O",
        "outputId": "51d4414f-8b65-4bc8-cdce-8c738e77a42a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-10 20:10:20--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2021-12-10 20:10:21--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2021-12-10 20:10:21--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip.1’\n",
            "\n",
            "glove.6B.zip.1      100%[===================>] 822.24M  5.05MB/s    in 2m 40s  \n",
            "\n",
            "2021-12-10 20:13:01 (5.13 MB/s) - ‘glove.6B.zip.1’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: glove.6B.50d.txt        \n",
            "replace glove.6B.100d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: glove.6B.100d.txt       \n",
            "replace glove.6B.200d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: glove.6B.200d.txt       \n",
            "replace glove.6B.300d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load fasttext embeddings\n",
        "print('loading word embeddings...')\n",
        "fasttext_embedding = {}\n",
        "f = codecs.open('cc.tr.300.vec', encoding='utf-8')\n",
        "for line in tqdm(f):\n",
        "    values = line.rstrip().rsplit(' ')\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    fasttext_embedding[word] = coefs\n",
        "f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aspnM-Nuu9gr",
        "outputId": "bf963410-a916-4f86-e98c-fa82a2981bff"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading word embeddings...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2000001it [04:20, 7665.32it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fasttext_embedding['güzel'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6fSrp-kuu9jc",
        "outputId": "9cedfeb2-161f-4842-d23c-a0fabdff924e"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove = pd.read_csv('glove.6B.300d.txt', sep=\" \", quoting=3, header=None, index_col=0)\n",
        "glove_embedding = {key: val.values for key, val in glove.T.items()}"
      ],
      "metadata": {
        "id": "RuLr9biku9mR"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check check the dimension of this fasttext embedding version\n",
        "\n",
        "glove_embedding['guzel'].shape"
      ],
      "metadata": {
        "id": "JErcCUzbu9ou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5199b2c4-ac23-4271-f465-6af35601c6a1"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Building model **pipeline**"
      ],
      "metadata": {
        "id": "vIBQe9f3y9_U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class hepsitrend:\n",
        "    def __init__(self, reviews, targets):\n",
        "        \"\"\"\n",
        "        Argument:\n",
        "        reviews: a numpy array\n",
        "        targets: a vector array\n",
        "        \n",
        "        Return xtrain and ylabel in torch tensor datatype, stored in dictionary format\n",
        "        \"\"\"\n",
        "        self.reviews = reviews\n",
        "        self.target = targets\n",
        "    \n",
        "    def __len__(self):\n",
        "        # return length of dataset\n",
        "        return len(self.reviews)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        # given an idex (item), return review and target of that index in torch tensor\n",
        "        review = torch.tensor(self.reviews[index,:], dtype = torch.long)\n",
        "        target = torch.tensor(self.target[index], dtype = torch.float)\n",
        "        \n",
        "        return {'review': review,\n",
        "                'target': target}"
      ],
      "metadata": {
        "id": "apq8pLZSu9ru"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTM(nn.Module):\n",
        "    def __init__(self, embedding_matrix):\n",
        "        \"\"\"\n",
        "        Given embedding_matrix: numpy array with vector for all words\n",
        "        return prediction ( in torch tensor format)\n",
        "        \"\"\"\n",
        "        super(LSTM, self).__init__()\n",
        "        # Number of words = number of rows in embedding matrix\n",
        "        num_words = embedding_matrix.shape[0]\n",
        "        # Dimension of embedding is num of columns in the matrix\n",
        "        embedding_dim = embedding_matrix.shape[1]\n",
        "        # Define an input embedding layer\n",
        "        self.embedding = nn.Embedding(\n",
        "                                      num_embeddings=num_words,\n",
        "                                      embedding_dim=embedding_dim)\n",
        "        # Embedding matrix actually is collection of parameter\n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype = torch.float32))\n",
        "        # Because we use pretrained embedding (GLove, Fastext,etc) so we turn off requires_grad-meaning we do not train gradient on embedding weight\n",
        "        self.embedding.weight.requires_grad = False\n",
        "        # LSTM with hidden_size = 128\n",
        "        self.lstm = nn.LSTM(\n",
        "                            embedding_dim, \n",
        "                            128,\n",
        "                            bidirectional=True,\n",
        "                            batch_first=True,\n",
        "                             )\n",
        "        # Input(512) because we use bi-directional LSTM ==> hidden_size*2 + maxpooling **2  = 128*4 = 512, will be explained more on forward method\n",
        "        self.out = nn.Linear(512, 1)\n",
        "    def forward(self, x):\n",
        "        # pass input (tokens) through embedding layer\n",
        "        x = self.embedding(x)\n",
        "        # fit embedding to LSTM\n",
        "        hidden, _ = self.lstm(x)\n",
        "        # apply mean and max pooling on lstm output\n",
        "        avg_pool= torch.mean(hidden, 1)\n",
        "        max_pool, index_max_pool = torch.max(hidden, 1)\n",
        "        # concat avg_pool and max_pool ( so we have 256 size, also because this is bidirectional ==> 256*2 = 512)\n",
        "        out = torch.cat((avg_pool, max_pool), 1)\n",
        "        # fit out to self.out to conduct dimensionality reduction from 512 to 1\n",
        "        out = self.out(out)\n",
        "        # return output\n",
        "        return out"
      ],
      "metadata": {
        "id": "QToymz6-u9uY"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data_loader, model, optimizer, device):\n",
        "    \"\"\"\n",
        "    this is model training for one epoch\n",
        "    data_loader:  this is torch dataloader, just like dataset but in torch and devide into batches\n",
        "    model : lstm\n",
        "    optimizer : torch optimizer : adam\n",
        "    device:  cuda or cpu\n",
        "    \"\"\"\n",
        "    # set model to training mode\n",
        "    model.train()\n",
        "    # go through batches of data in data loader\n",
        "    for data in data_loader:\n",
        "        reviews = data['review']\n",
        "        targets = data['target']\n",
        "        # move the data to device that we want to use\n",
        "        reviews = reviews.to(device, dtype = torch.long)\n",
        "        targets = targets.to(device, dtype = torch.float)\n",
        "        # clear the gradient\n",
        "        optimizer.zero_grad()\n",
        "        # make prediction from model\n",
        "        predictions = model(reviews)\n",
        "        # caculate the losses\n",
        "        loss = nn.BCEWithLogitsLoss()(predictions, targets.view(-1,1))\n",
        "        # backprob\n",
        "        loss.backward()\n",
        "        #single optimization step\n",
        "        optimizer.step()"
      ],
      "metadata": {
        "id": "egUcmJvYu9w_"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(data_loader, model, device):\n",
        "    final_predictions = []\n",
        "    final_targets = []\n",
        "    model.eval()\n",
        "    # turn off gradient calculation\n",
        "    with torch.no_grad():\n",
        "        for data in data_loader:\n",
        "            reviews = data['review']\n",
        "            targets = data['target']\n",
        "            reviews = reviews.to(device, dtype = torch.long)\n",
        "            targets = targets.to(device, dtype=torch.float)\n",
        "            # make prediction\n",
        "            predictions = model(reviews)\n",
        "            # move prediction and target to cpu\n",
        "            predictions = predictions.cpu().numpy().tolist()\n",
        "            targets = data['target'].cpu().numpy().tolist()\n",
        "            # add predictions to final_prediction\n",
        "            final_predictions.extend(predictions)\n",
        "            final_targets.extend(targets)\n",
        "    return final_predictions, final_targets"
      ],
      "metadata": {
        "id": "et_Ct809u9z2"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 600\n",
        "TRAIN_BATCH_SIZE = 512\n",
        "VALID_BATCH_SIZE = 512\n",
        "EPOCHS = 10"
      ],
      "metadata": {
        "id": "CQFelMqPc1qi"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_embedding_matrix(word_index, embedding_dict=None, d_model=100):\n",
        "    \"\"\"\n",
        "     this function create the embedding matrix save in numpy array\n",
        "    :param word_index: a dictionary with word: index_value\n",
        "    :param embedding_dict: a dict with word embedding\n",
        "    :d_model: the dimension of word pretrained embedding, here I just set to 100, we will define again\n",
        "    :return a numpy array with embedding vectors for all known words\n",
        "    \"\"\"\n",
        "    embedding_matrix = np.zeros((len(word_index) + 1, d_model))\n",
        "    ## loop over all the words\n",
        "    for word, index in word_index.items():\n",
        "        if word in embedding_dict:\n",
        "            embedding_matrix[index] = embedding_dict[word]\n",
        "    return embedding_matrix"
      ],
      "metadata": {
        "id": "xbl5rh10zLNZ"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Tokenization\n",
        "# use tf.keras for tokenization,  \n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts(data.yorum.values.tolist())"
      ],
      "metadata": {
        "id": "-67sF8jIzMvU"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Load fasttext embedding')\n",
        "embedding_matrix = create_embedding_matrix(tokenizer.word_index, embedding_dict=fasttext_embedding, d_model=300)\n",
        "\n",
        "# I just run 1 fold to reduce the time. You can try more fold to get better generalization\n",
        "for fold in range(1):\n",
        "    # STEP 2: cross validation\n",
        "    train_df = data[data.kfold != fold].reset_index(drop=True)\n",
        "    valid_df = data[data.kfold == fold].reset_index(drop=True)\n",
        "    \n",
        "    # STEP 3: pad sequence\n",
        "    xtrain = tokenizer.texts_to_sequences(train_df.yorum.values)\n",
        "    xtest = tokenizer.texts_to_sequences(valid_df.yorum.values)\n",
        "    \n",
        "    # zero padding\n",
        "    xtrain = tf.keras.preprocessing.sequence.pad_sequences(xtrain, maxlen=MAX_LEN)\n",
        "    xtest = tf.keras.preprocessing.sequence.pad_sequences(xtest, maxlen=MAX_LEN)\n",
        "    \n",
        "    # STEP 4: initialize dataset class for training\n",
        "    train_dataset = hepsitrend(reviews=xtrain, targets=train_df.sentiment.values)\n",
        "    \n",
        "    # STEP 5: Load dataset to Pytorch DataLoader\n",
        "    # after we have train_dataset, we create a torch dataloader to load train_dataset class based on specified batch_size\n",
        "    train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size = TRAIN_BATCH_SIZE, num_workers=2)\n",
        "    # initialize dataset class for validation\n",
        "    valid_dataset = hepsitrend(reviews=xtest, targets=valid_df.sentiment.values)\n",
        "    valid_data_loader = torch.utils.data.DataLoader(valid_dataset, batch_size = VALID_BATCH_SIZE, num_workers=1)\n",
        "    \n",
        "    # STEP 6: Running \n",
        "    device = torch.device('cuda')\n",
        "    # feed embedding matrix to lstm\n",
        "    model_fasttext = LSTM(embedding_matrix)\n",
        "    # set model to cuda device\n",
        "    model_fasttext.to(device)\n",
        "    # initialize Adam optimizer\n",
        "    optimizer = torch.optim.Adam(model_fasttext.parameters(), lr=1e-3)\n",
        "    \n",
        "    print('training model')\n",
        "   \n",
        "    for epoch in range(EPOCHS):\n",
        "        #train one epoch\n",
        "        train(train_data_loader, model_fasttext, optimizer,device)\n",
        "        #validate\n",
        "        outputs, targets = evaluate(valid_data_loader, model_fasttext,device)\n",
        "        # threshold\n",
        "        outputs = np.array(outputs) >= 0.5\n",
        "        # calculate accuracy\n",
        "        accuracy = metrics.accuracy_score(targets, outputs)\n",
        "        print(f'FOLD:{fold}, epoch: {epoch}, accuracy_score: {accuracy}')"
      ],
      "metadata": {
        "id": "NzfWljcczPTz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd5c61bd-6f5d-4c8a-8df0-e1fd02b14d04"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load fasttext embedding\n",
            "training model\n",
            "FOLD:0, epoch: 0, accuracy_score: 0.7085\n",
            "FOLD:0, epoch: 1, accuracy_score: 0.7807\n",
            "FOLD:0, epoch: 2, accuracy_score: 0.8103\n",
            "FOLD:0, epoch: 3, accuracy_score: 0.8123\n",
            "FOLD:0, epoch: 4, accuracy_score: 0.8189\n",
            "FOLD:0, epoch: 5, accuracy_score: 0.823\n",
            "FOLD:0, epoch: 6, accuracy_score: 0.8347\n",
            "FOLD:0, epoch: 7, accuracy_score: 0.8369\n",
            "FOLD:0, epoch: 8, accuracy_score: 0.836\n",
            "FOLD:0, epoch: 9, accuracy_score: 0.8394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Glove embedding ¶"
      ],
      "metadata": {
        "id": "1iD7rp-X7ENR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Load Glove embedding')\n",
        "embedding_matrix = create_embedding_matrix(tokenizer.word_index, embedding_dict=glove_embedding, d_model=300)\n",
        "\n",
        "for fold in range(1):\n",
        "    # STEP 2: cross validation\n",
        "    train_df = data[data.kfold != fold].reset_index(drop=True)\n",
        "    valid_df = data[data.kfold == fold].reset_index(drop=True)\n",
        "    \n",
        "    # STEP 3: pad sequence\n",
        "    xtrain = tokenizer.texts_to_sequences(train_df.yorum.values)\n",
        "    xtest = tokenizer.texts_to_sequences(valid_df.yorum.values)\n",
        "    \n",
        "    # zero padding\n",
        "    xtrain = tf.keras.preprocessing.sequence.pad_sequences(xtrain, maxlen=MAX_LEN)\n",
        "    xtest = tf.keras.preprocessing.sequence.pad_sequences(xtest, maxlen=MAX_LEN)\n",
        "    \n",
        "    # STEP 4: initialize dataset class for training\n",
        "    train_dataset = hepsitrend(reviews=xtrain, targets=train_df.sentiment.values)\n",
        "    \n",
        "    # STEP 5: Load dataset to Pytorch DataLoader\n",
        "    # after we have train_dataset, we create a torch dataloader to load train_dataset class based on specified batch_size\n",
        "    train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size = TRAIN_BATCH_SIZE, num_workers=2)\n",
        "    # initialize dataset class for validation\n",
        "    valid_dataset = hepsitrend(reviews=xtest, targets=valid_df.sentiment.values)\n",
        "    valid_data_loader = torch.utils.data.DataLoader(valid_dataset, batch_size = VALID_BATCH_SIZE, num_workers=1)\n",
        "    \n",
        "    # STEP 6: Running \n",
        "    device = torch.device('cuda')\n",
        "    # feed embedding matrix to lstm\n",
        "    model_glove = LSTM(embedding_matrix)\n",
        "    # set model to cuda device\n",
        "    model_glove.to(device)\n",
        "    # initialize Adam optimizer\n",
        "    optimizer = torch.optim.Adam(model_glove.parameters(), lr=1e-3)\n",
        "    \n",
        "    print('training model')\n",
        "   \n",
        "    for epoch in range(EPOCHS):\n",
        "        #train one epoch\n",
        "        train(train_data_loader, model_glove, optimizer, device)\n",
        "        #validate\n",
        "        outputs, targets = evaluate(valid_data_loader, model_glove, device)\n",
        "        # threshold\n",
        "        outputs = np.array(outputs) >= 0.5\n",
        "        # calculate accuracy\n",
        "        accuracy = metrics.accuracy_score(targets, outputs)\n",
        "        print(f'FOLD:{fold}, epoch: {epoch}, accuracy_score: {accuracy}')"
      ],
      "metadata": {
        "id": "EEy7CwhPzQs7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ced1ae1-77d4-432f-acd5-bdef80bcb7cb"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Load Glove embedding\n",
            "training model\n",
            "FOLD:0, epoch: 0, accuracy_score: 0.6257\n",
            "FOLD:0, epoch: 1, accuracy_score: 0.6449\n",
            "FOLD:0, epoch: 2, accuracy_score: 0.6497\n",
            "FOLD:0, epoch: 3, accuracy_score: 0.6593\n",
            "FOLD:0, epoch: 4, accuracy_score: 0.6682\n",
            "FOLD:0, epoch: 5, accuracy_score: 0.6678\n",
            "FOLD:0, epoch: 6, accuracy_score: 0.6649\n",
            "FOLD:0, epoch: 7, accuracy_score: 0.6645\n",
            "FOLD:0, epoch: 8, accuracy_score: 0.6671\n",
            "FOLD:0, epoch: 9, accuracy_score: 0.6706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Interact_user_input(model):\n",
        "    '''\n",
        "    model: trained model : fasttext model or glove model\n",
        "    '''\n",
        "    model.eval()\n",
        "    \n",
        "    sentence = ''\n",
        "    while True:\n",
        "        try:\n",
        "            sentence = input('Review: ')\n",
        "            if sentence in ['q','quit']: \n",
        "                break\n",
        "            sentence = np.array([sentence])\n",
        "            sentence_token = tokenizer.texts_to_sequences(sentence)\n",
        "            sentence_token = tf.keras.preprocessing.sequence.pad_sequences(sentence_token, maxlen = MAX_LEN)\n",
        "            sentence_train = torch.tensor(sentence_token, dtype = torch.long).to(device, dtype = torch.long)\n",
        "            predict = model(sentence_train)\n",
        "            if predict.item() > 0.5:\n",
        "                print('------> Positive')\n",
        "            else:\n",
        "                print('------> Negative')\n",
        "        except KeyError:\n",
        "            print('please enter again')"
      ],
      "metadata": {
        "id": "-jcM6P547LpD"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "rxv2Ba4PAe1w",
        "outputId": "5719b77a-4ade-411a-e7e2-66bfdb47ff74"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>yildizSayisi</th>\n",
              "      <th>yorum</th>\n",
              "      <th>yorumLike</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>kfold</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4</td>\n",
              "      <td>makinaya havlu veya fazla çamaşır attığımda ti...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>Ürün güzel yanlız tek kötü yanı saçı çekiştirm...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>sorunsuz çalişıyor</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5</td>\n",
              "      <td>Sorunsuz hizli sekilde teslim aldim. Tasarim o...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>Teknoloji işi şans biraz  çok memnun olan arka...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>3</td>\n",
              "      <td>henüz denemedim kargo başarılıydı fakat keşke ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>5</td>\n",
              "      <td>ürünün kendisini.ısmarladım .ama beyazı ğeldi....</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>2</td>\n",
              "      <td>Fiyat gümüş bi kipe için gayet iyi ama küpe ya...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>2</td>\n",
              "      <td>Birkaç kez kullanılabiliyor hemen karardı</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>2</td>\n",
              "      <td>gzeldi  ama saclarm ince die değiştmm düzlesmedi</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       yildizSayisi  ... kfold\n",
              "0                 4  ...     0\n",
              "1                 3  ...     0\n",
              "2                 5  ...     0\n",
              "3                 5  ...     0\n",
              "4                 2  ...     0\n",
              "...             ...  ...   ...\n",
              "49995             3  ...     4\n",
              "49996             5  ...     4\n",
              "49997             2  ...     4\n",
              "49998             2  ...     4\n",
              "49999             2  ...     4\n",
              "\n",
              "[50000 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.iloc[3][\"yorum\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jvYzetsbHdt7",
        "outputId": "8d1a256d-f60f-41ca-c677-66eedb9c3ed4"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Sorunsuz hizli sekilde teslim aldim. Tasarim olarak guzel, kullanim acisindan da memnunum.'"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Interact_user_input(model_fasttext)"
      ],
      "metadata": {
        "id": "XHPoVecv7Wej",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cefa1bd-5d15-452f-8dfc-4ae6f5763f9d"
      },
      "execution_count": 93,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Review: Sorunsuz hizli sekilde teslim aldim. Tasarim olarak guzel, kullanim acisindan da memnunum.\n",
            "------> Positive\n",
            "Review: q\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qnTWhKHJHxnY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}